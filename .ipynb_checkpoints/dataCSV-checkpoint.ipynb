{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import urllib.request\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd \n",
    "\n",
    "import FeatureExtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic class\n",
    "class KeywordCount:\n",
    "    def __init__(self, fname):\n",
    "        self.name = fname  #file name of input transcript\n",
    "        #init for updateWordCount()\n",
    "        self.words = []  #sequenced word list\n",
    "        self.wordCount = defaultdict(int)  #dictionary of words and their count\n",
    "        self.wordCountSort = defaultdict(int)  #sorted dictionary\n",
    "        self.transSize = 0  #words the transcript have\n",
    "        self.transSizeNS = 0  #meaningful words the transcript have\n",
    "        self.wordsetSize = 0  #all different words\n",
    "        #init for updateKeywordStatistics()\n",
    "        self.keywordStat = defaultdict(dict)  #num(int) certain keyword appears in the transcript\n",
    "        self.keywordStatSorted = defaultdict(dict)\n",
    "        self.keywordLoc = defaultdict(dict)  #locations(list) certain keyword appears in the transcript\n",
    "        self.keywordPart = defaultdict(dict)  #percentage per keyword from all keywords\n",
    "        self.keywordPer = float(0)  #percentage all keywords from all words\n",
    "        #init for questionMark()\n",
    "        self.questionStat = 0\n",
    "        self.questionLoc = []\n",
    "        self.questionPer = float(0)\n",
    "        #init for emoVoice()\n",
    "        self.emoTerm = []\n",
    "        self.emoLoc = []\n",
    "        #init for keywordQuestionmark()\n",
    "        self.keywordQNum = defaultdict(dict)\n",
    "        self.keywordQPer = defaultdict(dict)\n",
    "        self.keywordQOutput = defaultdict(dict)\n",
    "        #init for nonSpeech()\n",
    "        self.nSpeech = []\n",
    "        #init for lengthByTurn()\n",
    "        self.listTurn = []\n",
    "\n",
    "        print(\"Reading data...\")\n",
    "        print(\"Parsing by words...\")\n",
    "        with open(fname, encoding='utf-8', errors='ignore') as f:\n",
    "            data = f.read()\n",
    "        tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "        self.data = tokenizer.tokenize(data)\n",
    "        print(\"Parsing by sentences...\")\n",
    "        from nltk.tokenize import sent_tokenize\n",
    "        self.sentNum = 0\n",
    "        self.sents = []\n",
    "        with open(fname, encoding='utf-8', errors='ignore') as f:\n",
    "            for line in f:\n",
    "                line = line.lower()\n",
    "                self.sentNum += len(sent_tokenize(line))\n",
    "                for sent in sent_tokenize(line):\n",
    "                    self.sents.append(sent)\n",
    "\n",
    "        print(\"done\")\n",
    "\n",
    "        print(\"Initializing keword dictionary...\")\n",
    "        # Dictionary of key-terms for CTS fidelity\n",
    "        self.keywordCTS = defaultdict(set)\n",
    "\n",
    "        self.keywordCTS['Agenda'] = {'agenda','priorities','priority','do first','most important','work on','focus on','talk about' \\\n",
    "                                     ,'plan','todo list' ,'focus on first','focus on today','focus on during the session' \\\n",
    "                                     ,'talk about today','talk about first','talk about during the session' \\\n",
    "                                     ,'work on today','work on first','work on during the session' \\\n",
    "                                     ,'you like to','you want to','add to the agenda','add anything to the agenda','last week' \\\n",
    "                                     ,'evidence','mistake in thinking','what did you think','what did you want' \\\n",
    "                                     ,'how did you feel'}\n",
    "\n",
    "        self.keywordCTS['Feedback'] = {'feedback','reaction','advise','advice','suggestion','previous','last time','last week','last session','past session' \\\n",
    "                                       ,'think about today','things go today','think about today\\'s session','concern' \\\n",
    "                                       ,'what question','what questions','unhelpful','helpful','least helpful','about today\\'s session' \\\n",
    "                                       ,'anything i can do better','anything we can do better','concerns about today\\'s session','helpful about the session' \\\n",
    "                                       ,'can help you','we can try','learn','take in','skill','learn skills','achieve','goals','goal' \\\n",
    "                                       ,'if i understand you correctly','are you saying','do i have it right','work on your goals' \\\n",
    "                                       ,'was this helpful','how am i doing today','am i explaining things clearly','do you understand' \\\n",
    "                                       ,'do you follow me'}\n",
    "\n",
    "        self.keywordCTS['Understanding'] = {'understand','understanding','recognize','observe','grasp','comprehend','know','understand why' \\\n",
    "                                            ,'sounds like','you are saying','you were feeling','you felt','i felt','i was feeling' \\\n",
    "                                            ,'see','makes sense','i see','feel that way','feel this way'}\n",
    "\n",
    "        self.keywordCTS['Interpersonal Effectiveness'] = {'sorry','hard','difficult','tough' \\\n",
    "                                                          ,'dissappointing','stressful','stressed' \\\n",
    "                                                          ,'scary','frightening','upset','upsetting'\\\n",
    "                                                          ,'unfortunate'}\n",
    "\n",
    "        self.keywordCTS['Collaboration'] = {'choice', 'you want to do','good idea','because','will','help you get your goal'}\n",
    "\n",
    "        self.keywordCTS['Guided Discovery'] = {'meaning','mean','self','how','why','evidence' \\\n",
    "                                               ,'conclusion','conclude','decide','decision','decided' \\\n",
    "                                               ,'know','proof','tell me more','assume','assumption' \\\n",
    "                                               ,'hypothesis','disprove','facts','fact','solutions' \\\n",
    "                                               ,'brainstorm','solve','alternative','other explanations' \\\n",
    "                                               ,'another way','other way','to think about','to explain','reason'}\n",
    "\n",
    "        self.keywordCTS['Focus on Key Cognitions'] = {'thinking','tell yourself','through your mind' \\\n",
    "                                                      ,'what did you tell yourself','what went through your mind' \\\n",
    "                                                      ,'thought','think','connection','lead to','connected' \\\n",
    "                                                      ,'connect','link','linked','make you','you do','feel about the thought'}\n",
    "\n",
    "        self.keywordCTS['Choices of Intervention'] = {}\n",
    "\n",
    "        self.keywordCTS['Homework'] = {'homework','review','homework review','at home','practice','assignment','assign','get in the way of','work around' \\\n",
    "                                       ,'assigned','progress','learned','improve','learn','skills','skill','out of session','outside of session' \\\n",
    "                                       ,'goal','better','barrier','in the way','expect','problems','problem','succeed','success'}\n",
    "\n",
    "        self.keywordCTS['Social Skills Training'] = {'rational','help you learn this skill','help you with your goal' \\\n",
    "                                                     ,'demonstrate','to make your next role','play better','play even better' \\\n",
    "                                                     ,'try to focus on','do well','did well','did a good job' \\\n",
    "                                                     ,'for the next role play','recommend focusing on'}\n",
    "\n",
    "\n",
    "    def updateWordCount(self):\n",
    "        print('Starting counting words...')\n",
    "        stopWords = set(stopwords.words(\"english\"))\n",
    "        # Ignore capitalization and remove punctuation\n",
    "        punctuation = set(string.punctuation)\n",
    "        stemmer = PorterStemmer()\n",
    "        for d in self.data:\n",
    "            r = ''.join([c for c in d if not c in punctuation])\n",
    "            if r != '':\n",
    "                w = stemmer.stem(r.lower())\n",
    "                self.words.append(w)\n",
    "                self.transSize += 1\n",
    "                if not w in stopWords:\n",
    "                    self.wordCount[w] += 1\n",
    "                    self.transSizeNS += 1\n",
    "        self.wordsetSize = len(self.wordCount)\n",
    "        self.wordCountSort = sorted(self.wordCount.items(), key = lambda kv: kv[1])\n",
    "        print('Word counting done.')\n",
    "\n",
    "    def updateKeywordStatistics(self):\n",
    "        print('Starting keyword statisics...')\n",
    "        s = 0\n",
    "        for k1 in self.keywordCTS.keys():\n",
    "            for k2 in self.keywordCTS[k1]:\n",
    "                self.keywordStat[k1][k2] = 0\n",
    "                if len(k2.split()) == 1:\n",
    "                    if k2 in self.wordCount.keys():\n",
    "                        self.keywordStat[k1][k2] = self.wordCount[k2]\n",
    "                        s += self.wordCount[k2]\n",
    "                        loc = []\n",
    "                        cap = len(self.words)\n",
    "                        for i in range(cap):\n",
    "                            if self.words[i] == k2:\n",
    "                                loc.append(float(i)/float(cap))\n",
    "                        self.keywordLoc[k1][k2] = loc\n",
    "                else:\n",
    "                    loc = []\n",
    "                    for i in range(self.sentNum):\n",
    "                        if k2 in self.sents[i]:\n",
    "                            self.keywordStat[k1][k2] += self.sents[i].count(k2)\n",
    "                            s += self.sents[i].count(k2)\n",
    "                            for j in range(self.sents[i].count(k2)):\n",
    "                                loc.append(float(i)/float(self.sentNum))\n",
    "                    if self.keywordStat[k1][k2] > 0:\n",
    "                        self.keywordLoc[k1][k2] = loc\n",
    "        for k1 in self.keywordStat.keys():\n",
    "        \tself.keywordStatSorted[k1] = sorted(self.keywordStat[k1].items(), key = lambda kv: kv[1])\n",
    "        for k1 in self.keywordStat.keys():\n",
    "            for k2 in self.keywordStat[k1].keys():\n",
    "                self.keywordPart[k1][k2] = self.keywordStat[k1][k2]/float(s)\n",
    "        self.keywordPer = s/float(self.transSize)\n",
    "        print('Keyword statistics done.')\n",
    "\n",
    "    def questionMark(self):\n",
    "        print('Starting questionmark statistics...')\n",
    "        l = len(self.data)\n",
    "        for i in range(l):\n",
    "            if self.data[i] == '?':\n",
    "                self.questionStat += 1\n",
    "                self.questionLoc.append(float(i)/float(l))\n",
    "        self.questionPer = float(self.questionStat)/float(self.sentNum)\n",
    "        print('Questionmark statistics done.')\n",
    "\n",
    "    def emoVoice(self):\n",
    "        i = 0\n",
    "        with open(self.name, encoding='utf-8', errors='ignore') as f:\n",
    "            for line in f:\n",
    "                line = line.lower()\n",
    "                if not (line[0] == 'p' or line[0] == 'c'):\n",
    "                    self.emoTerm.append(line)\n",
    "                    self.emoLoc.append((line,float(i)/float(self.sentNum)))\n",
    "                i += 1\n",
    "\n",
    "    def keywordQuestionmark(self):\n",
    "        print('Starting keyword in questionmarks statistics...')\n",
    "        for k1 in self.keywordCTS.keys():\n",
    "            for k2 in self.keywordCTS[k1]:\n",
    "                if self.keywordStat[k1][k2] > 0:\n",
    "                    self.keywordQNum[k1][k2] = 0\n",
    "                    for s in self.sents:\n",
    "                        self.keywordQNum[k1][k2] += int('?' in s * s.count(k2))\n",
    "                    self.keywordQPer[k1][k2] = float(self.keywordQNum[k1][k2])/self.keywordStat[k1][k2]\n",
    "                    self.keywordQOutput[k1][k2] = (self.keywordQNum[k1][k2],self.keywordStat[k1][k2],self.keywordQPer[k1][k2])\n",
    "        print('keyword with questionmarks statistics done.')\n",
    "\n",
    "    def nonSpeech(self):\n",
    "        with open(self.name, encoding='utf-8', errors='ignore') as f:\n",
    "            data = f.read()\n",
    "        flag = False\n",
    "        start = []\n",
    "        end = []\n",
    "        for i in range(len(data)):\n",
    "            if data[i] == '[':\n",
    "                start.append(i)\n",
    "                j = i\n",
    "                flag = True\n",
    "                while(flag == True and j < len(data)-1):\n",
    "                    j += 1\n",
    "                    if data[j] == ']' or j == len(data)-1:\n",
    "                        break\n",
    "                if data[j] == ']':\n",
    "                    end.append(j)\n",
    "        for k in range(len(end)):\n",
    "            self.nSpeech.append(data[start[k]:end[k]+1])\n",
    "\n",
    "    def lengthByTurn(self):\n",
    "        tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "        with open(self.name, encoding='utf-8', errors='ignore') as f:\n",
    "            for line in f:\n",
    "                line = line.lower()\n",
    "                if (line[0] == 'c'):\n",
    "                    self.listTurn.append(('c',len(tokenizer.tokenize(line))))\n",
    "                elif (line[0] == 'p'):\n",
    "                    self.listTurn.append(('p',len(tokenizer.tokenize(line))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_mark</th>\n",
       "      <th>agenda</th>\n",
       "      <th>learn</th>\n",
       "      <th>goal</th>\n",
       "      <th>homework</th>\n",
       "      <th>homework_review</th>\n",
       "      <th>in_the_way</th>\n",
       "      <th>assign</th>\n",
       "      <th>think</th>\n",
       "      <th>thought</th>\n",
       "      <th>make_you</th>\n",
       "      <th>you_do</th>\n",
       "      <th>you_want_to</th>\n",
       "      <th>add_anything_to_the_agenda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T3</th>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T4</th>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T5</th>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T6</th>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T7</th>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_mark agenda learn goal homework homework_review in_the_way  \\\n",
       "T1             20    NaN   NaN  NaN      NaN             NaN        NaN   \n",
       "T3             30    NaN   NaN  NaN      NaN             NaN        NaN   \n",
       "T4             40    NaN   NaN  NaN      NaN             NaN        NaN   \n",
       "T5             50    NaN   NaN  NaN      NaN             NaN        NaN   \n",
       "T6             60    NaN   NaN  NaN      NaN             NaN        NaN   \n",
       "T7             70    NaN   NaN  NaN      NaN             NaN        NaN   \n",
       "\n",
       "   assign think thought make_you you_do you_want_to add_anything_to_the_agenda  \n",
       "T1    NaN   NaN     NaN      NaN    NaN         NaN                        NaN  \n",
       "T3    NaN   NaN     NaN      NaN    NaN         NaN                        NaN  \n",
       "T4    NaN   NaN     NaN      NaN    NaN         NaN                        NaN  \n",
       "T5    NaN   NaN     NaN      NaN    NaN         NaN                        NaN  \n",
       "T6    NaN   NaN     NaN      NaN    NaN         NaN                        NaN  \n",
       "T7    NaN   NaN     NaN      NaN    NaN         NaN                        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domainIndexOfKeywords = {  \"Agenda\":[\"agenda\",\"you want to\",\"add anything to the agenda\"] \\\n",
    "                         , \"Feedback\":[\"learn\",\"goal\"] \\\n",
    "                         , \"Homework\":[\"homework\",\"homework review\",\"in the way\",\"assign\"] \\\n",
    "                         , \"Focus on Key Cognitions\":[\"think\",\"thought\",\"make you\",\"you do\"]  }           \n",
    "index = [\"T1\",\"T3\",\"T4\",\"T5\",\"T6\",\"T7\"]\n",
    "columns = [\"question_mark\",\"agenda\",\"learn\",\"goal\",\"homework\",\"homework_review\",\"in_the_way\" \\\n",
    "           ,\"assign\",\"think\",\"thought\",\"make_you\",\"you_do\",\"you_want_to\" \\\n",
    "           ,\"add_anything_to_the_agenda\"]\n",
    "df = pd.DataFrame(index = index, columns = columns)\n",
    "with open('numericAttributes.csv', 'a') as f:\n",
    "    df.to_csv(f, header = False)\n",
    "df[\"question_mark\"] = [20,30,40,50,60,70]\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
