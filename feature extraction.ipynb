{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import urllib.request\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "class KeywordCount:\n",
    "    def __init__(self, fname):\n",
    "        self.name = fname  #file name of input transcript\n",
    "        #init for updateWordCount()\n",
    "        self.words = []  #sequenced word list\n",
    "        self.wordCount = defaultdict(int)  #dictionary of words and their count\n",
    "        self.wordCountSort = defaultdict(int)  #sorted dictionary\n",
    "        self.transSize = 0  #words the transcript have\n",
    "        self.transSizeNS = 0  #meaningful words the transcript have\n",
    "        self.wordsetSize = 0  #all different words\n",
    "        #init for updateKeywordStatistics()\n",
    "        self.keywordStat = defaultdict(dict)  #num(int) certain keyword appears in the transcript\n",
    "        self.keywordStatSorted = defaultdict(dict)\n",
    "        self.keywordLoc = defaultdict(dict)  #locations(list) certain keyword appears in the transcript\n",
    "        self.keywordPart = defaultdict(dict)  #percentage per keyword from all keywords\n",
    "        self.keywordPer = float(0)  #percentage all keywords from all words\n",
    "        #init for questionMark()\n",
    "        self.questionStat = 0\n",
    "        self.questionLoc = []\n",
    "        self.questionPer = float(0)\n",
    "        #init for emoVoice()\n",
    "        self.emoTerm = []\n",
    "        self.emoLoc = []\n",
    "        print(\"Reading data...\")\n",
    "        print(\"Parsing by words...\")\n",
    "        with open(fname, encoding='utf-8', errors='ignore') as f:\n",
    "            data = f.read()\n",
    "        tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "        self.data = tokenizer.tokenize(data)\n",
    "        print(\"Parsing by sentences...\")\n",
    "        from nltk.tokenize import sent_tokenize\n",
    "        self.sentNum = 0 \n",
    "        self.sents = []\n",
    "        with open(fname, encoding='utf-8', errors='ignore') as f:\n",
    "            for line in f:\n",
    "                line = line.lower()\n",
    "                self.sentNum += len(sent_tokenize(line))\n",
    "                for sent in sent_tokenize(line):\n",
    "                    self.sents.append(sent)\n",
    "\n",
    "        print(\"done\")\n",
    "\n",
    "        print(\"Initializing keword dictionary...\")\n",
    "        # Dictionary of key-terms for CTS fidelity\n",
    "        self.keywordCTS = defaultdict(set)\n",
    "\n",
    "        self.keywordCTS['Agenda'] = {'agenda','priorities','priority','do first','most important','work on','focus on','talk about' \\\n",
    "                                     ,'plan','todo list' ,'focus on first','focus on today','focus on during the session' \\\n",
    "                                     ,'talk about today','talk about first','talk about during the session' \\\n",
    "                                     ,'work on today','work on first','work on during the session' \\\n",
    "                                     ,'you like to','you want to','add to the agenda','add anything to the agenda','last week' \\\n",
    "                                     ,'evidence','mistake in thinking','what did you think','what did you want' \\\n",
    "                                     ,'how did you feel'}\n",
    "\n",
    "        self.keywordCTS['Feedback'] = {'feedback','reaction','advise','advice','suggestion','previous','last time','last week','last session','past session' \\\n",
    "                                       ,'think about today','things go today','think about today\\'s session','concern' \\\n",
    "                                       ,'what question','what questions','unhelpful','helpful','least helpful','about today\\'s session' \\\n",
    "                                       ,'anything i can do better','anything we can do better','concerns about today\\'s session','helpful about the session' \\\n",
    "                                       ,'can help you','we can try','learn','take in','skill','learn skills','achieve','goals','goal' \\\n",
    "                                       ,'if i understand you correctly','are you saying','do i have it right','work on your goals' \\\n",
    "                                       ,'was this helpful','how am i doing today','am i explaining things clearly','do you understand' \\\n",
    "                                       ,'do you follow me'}\n",
    "\n",
    "        self.keywordCTS['Understanding'] = {'understand','understanding','recognize','observe','grasp','comprehend','know','understand why' \\\n",
    "                                            ,'sounds like','you are saying','you were feeling','you felt','i felt','i was feeling' \\\n",
    "                                            ,'see','makes sense','i see','feel that way','feel this way'}\n",
    "\n",
    "        self.keywordCTS['Interpersonal Effectiveness'] = {'sorry','hard','difficult','tough' \\\n",
    "                                                          ,'dissappointing','stressful','stressed' \\\n",
    "                                                          ,'scary','frightening','upset','upsetting'\\\n",
    "                                                          ,'unfortunate'}\n",
    "\n",
    "        self.keywordCTS['Collaboration'] = {'choice', 'you want to do','good idea','because','will','help you get your goal'}\n",
    "\n",
    "        self.keywordCTS['Guided Discovery'] = {'meaning','mean','self','how','why','evidence' \\\n",
    "                                               ,'conclusion','conclude','decide','decision','decided' \\\n",
    "                                               ,'know','proof','tell me more','assume','assumption' \\\n",
    "                                               ,'hypothesis','disprove','facts','fact','solutions' \\\n",
    "                                               ,'brainstorm','solve','alternative','other explanations' \\\n",
    "                                               ,'another way','other way','to think about','to explain','reason'} \n",
    "\n",
    "        self.keywordCTS['Focus on Key Cognitions'] = {'thinking','tell yourself','through your mind' \\\n",
    "                                                      ,'what did you tell yourself','what went through your mind' \\\n",
    "                                                      ,'thought','think','connection','lead to','connected' \\\n",
    "                                                      ,'connect','link','linked','make you','you do','feel about the thought'}\n",
    "\n",
    "        self.keywordCTS['Choices of Intervention'] = {}\n",
    "\n",
    "        self.keywordCTS['Homework'] = {'homework','review','at home','practice','assignment','assign','get in the way of','work around' \\\n",
    "                                       ,'assigned','progress','learned','improve','learn','skills','skill','out of session','outside of session' \\\n",
    "                                       ,'goal','better','barrier','in the way','expect','problems','problem','succeed','success'}\n",
    "\n",
    "        self.keywordCTS['Social Skills Training'] = {'rational','help you learn this skill','help you with your goal' \\\n",
    "                                                     ,'demonstrate','to make your next role','play better','play even better' \\\n",
    "                                                     ,'try to focus on','do well','did well','did a good job' \\\n",
    "                                                     ,'for the next role play','recommend focusing on'}\n",
    "                                                           \n",
    "\n",
    "    def updateWordCount(self):\n",
    "        print('Starting counting words...')\n",
    "        stopWords = set(stopwords.words(\"english\"))\n",
    "        # Ignore capitalization and remove punctuation\n",
    "        punctuation = set(string.punctuation)\n",
    "        stemmer = PorterStemmer()\n",
    "        for d in self.data:\n",
    "            r = ''.join([c for c in d if not c in punctuation])\n",
    "            if r != '':\n",
    "                w = stemmer.stem(r.lower())\n",
    "                self.words.append(w)\n",
    "                self.transSize += 1\n",
    "                if not w in stopWords:\n",
    "                    self.wordCount[w] += 1\n",
    "                    self.transSizeNS += 1\n",
    "        self.wordsetSize = len(self.wordCount)\n",
    "        self.wordCountSort = sorted(self.wordCount.items(), key = lambda kv: kv[1])\n",
    "        print('Word counting done.')\n",
    "\n",
    "    def updateKeywordStatistics(self):\n",
    "        print('Starting keyword statisics...')\n",
    "        s = 0\n",
    "        for k1 in self.keywordCTS.keys():\n",
    "            for k2 in self.keywordCTS[k1]:\n",
    "                self.keywordStat[k1][k2] = 0\n",
    "                if len(k2.split()) == 1:\n",
    "                    if k2 in self.wordCount.keys():\n",
    "                        self.keywordStat[k1][k2] = self.wordCount[k2]\n",
    "                        s += self.wordCount[k2]\n",
    "                        loc = []\n",
    "                        cap = len(self.words)\n",
    "                        for i in range(cap):\n",
    "                            if self.words[i] == k2:\n",
    "                                loc.append(float(i)/float(cap))\n",
    "                        self.keywordLoc[k1][k2] = loc\n",
    "                else: \n",
    "                    loc = []\n",
    "                    for i in range(self.sentNum):\n",
    "                        if k2 in self.sents[i]:\n",
    "                            self.keywordStat[k1][k2] += self.sents[i].count(k2)\n",
    "                            s += self.sents[i].count(k2)\n",
    "                            for j in range(self.sents[i].count(k2)):\n",
    "                                loc.append(float(i)/float(self.sentNum))\n",
    "                    if self.keywordStat[k1][k2] > 0:\n",
    "                        self.keywordLoc[k1][k2] = loc\n",
    "        for k1 in self.keywordStat.keys():\n",
    "            self.keywordStatSorted[k1] = sorted(self.keywordStat[k1].items(), key = lambda kv: kv[1])\n",
    "        for k1 in self.keywordStat.keys():\n",
    "            for k2 in self.keywordStat[k1].keys():\n",
    "                self.keywordPart[k1][k2] = self.keywordStat[k1][k2]/float(s)\n",
    "        self.keywordPer = s/float(self.transSize)\n",
    "        print('Keyword statistics done.')\n",
    "\n",
    "    def questionMark(self):\n",
    "        print('Starting questionmark statistics...')\n",
    "        l = len(self.data)\n",
    "        for i in range(l):\n",
    "            if self.data[i] == '?':\n",
    "                self.questionStat += 1\n",
    "                self.questionLoc.append(float(i)/float(l))\n",
    "        self.questionPer = float(self.questionStat)/float(self.sentNum)\n",
    "        print('Questionmark statistics done.')\n",
    "\n",
    "    def emoVoice(self):\n",
    "        i = 0\n",
    "        with open(self.name, encoding='utf-8', errors='ignore') as f:\n",
    "            for line in f:\n",
    "                line = line.lower()\n",
    "                if not (line[0] == 'p' or line[0] == 'c'):\n",
    "                    self.emoTerm.append(line)\n",
    "                    self.emoLoc.append((line,float(i)/float(self.sentNum)))\n",
    "                i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Parsing by words...\n",
      "Parsing by sentences...\n",
      "done\n",
      "Initializing keword dictionary...\n",
      "Starting counting words...\n",
      "Word counting done.\n",
      "Starting keyword statisics...\n",
      "Keyword statistics done.\n",
      "Starting questionmark statistics...\n",
      "Questionmark statistics done.\n"
     ]
    }
   ],
   "source": [
    "t1 = KeywordCount('Transcript1.txt')\n",
    "t1.updateWordCount()\n",
    "t1.updateKeywordStatistics()\n",
    "t1.questionMark()\n",
    "t1.emoVoice()\n",
    "f = open('Feature'+t1.name,'w')\n",
    "#file information\n",
    "f.write('File name: ' + t1.name + '\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('Object: ' + 'Overall' + '\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('Keyword Dictionary:' + '\\n')\n",
    "f.write(str(t1.keywordCTS))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "# 1. keywords & key phrases of each domain\n",
    "# 1-1. appearing times(sorted)\n",
    "f.write('Feature 1-1: times(int) certain keyword appears in the transcript ' + '\\n')\n",
    "f.write(str(t1.keywordStatSorted))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "#1-2. appearing locations(sequenced)\n",
    "f.write('Feature 1-2: locations(list of floats) certain keyword appears in the transcrip' + '\\n')\n",
    "f.write(str(t1.keywordLoc))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "# f.write('Feature 3: percentage per keyword from all keywords' + '\\n')\n",
    "# f.write(str(t1.keywordPart))\n",
    "# f.write('\\n')\n",
    "# f.write('========================================================================================' + '\\n')\n",
    "\n",
    "# 2. keywords & key phrases overall\n",
    "# 2-1. keywords/phrases percentage of all words\n",
    "f.write('Feature 2-1: percentage of all keywords from all words' + '\\n')\n",
    "f.write(str(t1.keywordPer))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "\n",
    "# 3. question marks, i.e. interrogative sentences \n",
    "# 3-1. appearing times\n",
    "# 3-2. appearing locations\n",
    "# 3-3. percentage of all sentences\n",
    "f.write('Feature 3-1: questionmarks count' + '\\n')\n",
    "f.write(str(t1.questionStat))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('Feature 3-2: questionmarks location' + '\\n')\n",
    "f.write(str(t1.questionLoc))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('Feature 3-3: percentage of sentences ending with questionmark from all sentences' + '\\n')\n",
    "f.write(str(t1.questionPer))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "\n",
    "# 4. speech length\n",
    "# 4-1. with metric of words with stopwords\n",
    "# 4-2. with metric of words without stopwords\n",
    "# 4-3. with metric of sentences\n",
    "f.write('Feature 4-1: speech length in metric of words with stopwords' + '\\n')\n",
    "f.write(str(t1.transSize))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('Feature 4-2: speech length in metric of words without stopwords' + '\\n')\n",
    "f.write(str(t1.transSizeNS))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('Feature 4-3: speech length in metric of sentences' + '\\n')\n",
    "f.write(str(t1.sentNum))\n",
    "f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelledKeywordCount(KeywordCount):\n",
    "    def __init__(self, fname, label):\n",
    "\n",
    "        self.name = fname  #file name of input transcript\n",
    "        self.label = label\n",
    "        #init for updateWordCount()\n",
    "        self.words = []  #sequenced word list\n",
    "        self.wordCount = defaultdict(int)  #dictionary of words and their count\n",
    "        self.wordCountSort = defaultdict(int)  #sorted dictionary\n",
    "        self.transSize = 0  #words the transcript have\n",
    "        self.transSizeNS = 0  #meaningful words the transcript have\n",
    "        self.wordsetSize = 0  #all different words\n",
    "        #init for updateKeywordStatistics()\n",
    "        self.keywordStat = defaultdict(dict)  #num(int) certain keyword appears in the transcript\n",
    "        self.keywordStatSorted = defaultdict(dict)\n",
    "        self.keywordLoc = defaultdict(dict)  #locations(list) certain keyword appears in the transcript\n",
    "        self.keywordPart = defaultdict(dict)  #percentage per keyword from all keywords\n",
    "        self.keywordPer = float(0)  #percentage all keywords from all words\n",
    "        #init for questionMark()\n",
    "        self.questionStat = 0\n",
    "        self.questionLoc = []\n",
    "        self.questionPer = float(0)\n",
    "        #init for emoVoice()\n",
    "        self.emoTerm = []\n",
    "        self.emoLoc = []\n",
    "\n",
    "        print(\"Reading data...\")\n",
    "        from nltk.tokenize import sent_tokenize\n",
    "        self.data = []\n",
    "        self.lines = []\n",
    "        self.sents = []\n",
    "        self.sentNum = 0 \n",
    "        with open(fname, encoding='utf-8', errors='ignore') as f:\n",
    "            for line in f:\n",
    "                line = line.lower()\n",
    "                if (line[0] == label):\n",
    "                    self.lines.append(sent_tokenize(line))\n",
    "                    for sent in sent_tokenize(line):\n",
    "                        self.sents.append(sent)\n",
    "                    self.sentNum += len(sent_tokenize(line))\n",
    "                    tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "                    self.data += tokenizer.tokenize(line)\n",
    "        print(\"done\")\n",
    "\n",
    "        print(\"Initializing keyword dictionary...\")\n",
    "        # Dictionary of key-terms for CTS fidelity\n",
    "        self.keywordCTS = defaultdict(set)\n",
    "\n",
    "        self.keywordCTS['Agenda'] = {'agenda','priorities','priority','do first','most important','work on','focus on','talk about' \\\n",
    "                                     ,'plan','todo list' ,'focus on first','focus on today','focus on during the session' \\\n",
    "                                     ,'talk about today','talk about first','talk about during the session' \\\n",
    "                                     ,'work on today','work on first','work on during the session' \\\n",
    "                                     ,'you like to','you want to','add to the agenda','add anything to the agenda','last week' \\\n",
    "                                     ,'evidence','mistake in thinking','what did you think','what did you want' \\\n",
    "                                     ,'how did you feel'}\n",
    "\n",
    "        self.keywordCTS['Feedback'] = {'feedback','reaction','advise','advice','suggestion','previous','last time','last week','last session','past session' \\\n",
    "                                       ,'think about today','things go today','think about today\\'s session','concern' \\\n",
    "                                       ,'what question','what questions','unhelpful','helpful','least helpful','about today\\'s session' \\\n",
    "                                       ,'anything i can do better','anything we can do better','concerns about today\\'s session','helpful about the session' \\\n",
    "                                       ,'can help you','we can try','learn','take in','skill','learn skills','achieve','goals','goal' \\\n",
    "                                       ,'if i understand you correctly','are you saying','do i have it right','work on your goals' \\\n",
    "                                       ,'was this helpful','how am i doing today','am i explaining things clearly','do you understand' \\\n",
    "                                       ,'do you follow me'}\n",
    "\n",
    "        self.keywordCTS['Understanding'] = {'understand','understanding','recognize','observe','grasp','comprehend','know','understand why' \\\n",
    "                                            ,'sounds like','you are saying','you were feeling','you felt','i felt','i was feeling' \\\n",
    "                                            ,'see','makes sense','i see','feel that way','feel this way'}\n",
    "\n",
    "        self.keywordCTS['Interpersonal Effectiveness'] = {'sorry','hard','difficult','tough' \\\n",
    "                                                          ,'dissappointing','stressful','stressed' \\\n",
    "                                                          ,'scary','frightening','upset','upsetting'\\\n",
    "                                                          ,'unfortunate'}\n",
    "\n",
    "        self.keywordCTS['Collaboration'] = {'choice', 'you want to do','good idea','because','will','help you get your goal'}\n",
    "\n",
    "        self.keywordCTS['Guided Discovery'] = {'meaning','mean','self','how','why','evidence' \\\n",
    "                                               ,'conclusion','conclude','decide','decision','decided' \\\n",
    "                                               ,'know','proof','tell me more','assume','assumption' \\\n",
    "                                               ,'hypothesis','disprove','facts','fact','solutions' \\\n",
    "                                               ,'brainstorm','solve','alternative','other explanations' \\\n",
    "                                               ,'another way','other way','to think about','to explain','reason'} \n",
    "\n",
    "        self.keywordCTS['Focus on Key Cognitions'] = {'thinking','tell yourself','through your mind' \\\n",
    "                                                      ,'what did you tell yourself','what went through your mind' \\\n",
    "                                                      ,'thought','think','connection','lead to','connected' \\\n",
    "                                                      ,'connect','link','linked','make you','you do','feel about the thought'}\n",
    "\n",
    "        self.keywordCTS['Choices of Intervention'] = {}\n",
    "\n",
    "        self.keywordCTS['Homework'] = {'homework','review','at home','practice','assignment','assign','get in the way of','work around' \\\n",
    "                                       ,'assigned','progress','learned','improve','learn','skills','skill','out of session','outside of session' \\\n",
    "                                       ,'goal','better','barrier','in the way','expect','problems','problem','succeed','success'}\n",
    "\n",
    "        self.keywordCTS['Social Skills Training'] = {'rational','help you learn this skill','help you with your goal' \\\n",
    "                                                     ,'demonstrate','to make your next role','play better','play even better' \\\n",
    "                                                     ,'try to focus on','do well','did well','did a good job' \\\n",
    "                                                     ,'for the next role play','recommend focusing on'}\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n",
      "Initializing keyword dictionary...\n",
      "Starting counting words...\n",
      "Word counting done.\n",
      "Starting keyword statisics...\n",
      "Keyword statistics done.\n",
      "Starting questionmark statistics...\n",
      "Questionmark statistics done.\n"
     ]
    }
   ],
   "source": [
    "t1 = LabelledKeywordCount('Transcript1.txt','c')\n",
    "t1.updateWordCount()\n",
    "t1.updateKeywordStatistics()\n",
    "t1.questionMark()\n",
    "t1.emoVoice()\n",
    "f = open('Label_'+t1.label+'_Feature_'+t1.name,'w')\n",
    "#file information\n",
    "f.write('File name: ' + t1.name + '\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('Object: ' + t1.label + '\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('Keyword Dictionary:' + '\\n')\n",
    "f.write(str(t1.keywordCTS))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "# 1. keywords & key phrases of each domain\n",
    "# 1-1. appearing times(sorted)\n",
    "f.write('Feature 1-1: times(int) certain keyword appears in the transcript ' + '\\n')\n",
    "f.write(str(t1.keywordStatSorted))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "#1-2. appearing locations(sequenced)\n",
    "f.write('Feature 1-2: locations(list of floats) certain keyword appears in the transcrip' + '\\n')\n",
    "f.write(str(t1.keywordLoc))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "# f.write('Feature 3: percentage per keyword from all keywords' + '\\n')\n",
    "# f.write(str(t1.keywordPart))\n",
    "# f.write('\\n')\n",
    "# f.write('========================================================================================' + '\\n')\n",
    "\n",
    "# 2. keywords & key phrases overall\n",
    "# 2-1. keywords/phrases percentage of all words\n",
    "f.write('Feature 2-1: percentage of all keywords from all words' + '\\n')\n",
    "f.write(str(t1.keywordPer))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "\n",
    "# 3. question marks, i.e. interrogative sentences \n",
    "# 3-1. appearing times\n",
    "# 3-2. appearing locations\n",
    "# 3-3. percentage of all sentences\n",
    "f.write('Feature 3-1: questionmarks count' + '\\n')\n",
    "f.write(str(t1.questionStat))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('Feature 3-2: questionmarks location' + '\\n')\n",
    "f.write(str(t1.questionLoc))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('Feature 3-3: percentage of sentences ending with questionmark from all sentences' + '\\n')\n",
    "f.write(str(t1.questionPer))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "\n",
    "# 4. speech length\n",
    "# 4-1. with metric of words with stopwords\n",
    "# 4-2. with metric of words without stopwords\n",
    "# 4-3. with metric of sentences\n",
    "f.write('Feature 4-1: speech length in metric of words with stopwords' + '\\n')\n",
    "f.write(str(t1.transSize))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('Feature 4-2: speech length in metric of words without stopwords' + '\\n')\n",
    "f.write(str(t1.transSizeNS))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('Feature 4-3: speech length in metric of sentences' + '\\n')\n",
    "f.write(str(t1.sentNum))\n",
    "f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
